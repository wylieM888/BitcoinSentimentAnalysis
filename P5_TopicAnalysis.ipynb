{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e045dc-4fff-4ff5-82b7-3fe5e425d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial By: Sashank Kapadia\n",
    "# Topic Modeling in Python: Latent Dirichlet Allocation (LDA)\n",
    "# https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338be833-0d81-46c2-a854-b3c854391a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Instantiate a dataframe using RedditData\n",
    "df = pd.read_csv('RedditData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8316af-5761-45b1-bb75-942fe3049355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Clean data by removing symbols and puncuations\n",
    "df['titles_processed'] = \\\n",
    "df['title'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "df['titles_processed'] = \\\n",
    "df['titles_processed'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea2ec2-198d-40b4-ac24-ad254df37272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load in NLTK Stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Stopwords added after viewing results\n",
    "stop_words.extend(['help', 'get', 'make', 'use', 'good', 'bitcoin', 'btc', 'crypto',\n",
    "                  'have', 'go', 'do', 'new', 'say', 'want', 'time', 'year', 'more', 'know', 'free', 'first', 'think', 'real',\n",
    "                  'would', 'need', 'https', 'us', 'anyone', 'el', 'one', 'question'])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # Create list of lowercased words from the sentence\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    # Return words to list if word is not in stopwords\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "# Create list object from new df column\n",
    "data = df.titles_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "# Remove stopwords from list\n",
    "data_words = remove_stopwords(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21fe3f-d29b-44ef-886f-cc496a6565e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create the dictionary using data_words\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "texts = data_words\n",
    "# Create a list that sets an id to word and frequency of that term\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a55fb9-bcc7-4284-9829-5b4b0a219f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word = id2word, \n",
    "                                            num_topics=15, random_state = 20, update_every = 1,\n",
    "                                            chunksize=1000, passes = 25, alpha = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e5fb23-58f0-4a26-9896-778fb776281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Data\n",
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Allow to run in-line and see visualization in Jyptiter\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30)\n",
    "\n",
    "# Top 15 words\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cea1c6-17b6-4ac0-9ff0-8758b72b5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the LDA Model\n",
    "lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec86d90-31e4-4e92-8de3-777672cac5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea1774-1a5f-4b4f-b252-718161e5d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b165ff6-1da1-46eb-9d40-983fc7251480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single string using the titles in the RedditData csv file\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "for i in df.title:\n",
    "    text += i + \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a75b9-74c7-4666-9861-fc55eaf750ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Font can be found here:\n",
    "# https://www.dafont.com/techfont.font\n",
    "font_path = 'C:/Users/guest1/Desktop/techfont/Techfont.ttf'\n",
    "\n",
    "# Bitcoin jpg can be found here:\n",
    "# https://icon-library.com/icon/bitcoin-icon-27.html\n",
    "mask = np.array(Image.open('C:/Users/guest1/Pictures/bitcoin-icon-27.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c4c238-c7f0-44f8-b230-67db30d29602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wordcloud object. \n",
    "wc = WordCloud(stopwords=stop_words, font_path=font_path,\n",
    "               mask=mask, background_color=\"white\",\n",
    "               max_words=2000, max_font_size=256)\n",
    "# Generate the WC object with created string\n",
    "wc.generate(text)\n",
    "# Increase the size of the figure to be printed\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# https://matplotlib.org/stable/gallery/images_contours_and_fields/interpolation_methods.html\n",
    "# interpolation manipulates how the text is displayed on the image\n",
    "plt.imshow(wc, interpolation=\"nearest\")\n",
    "# Make the axis invisible\n",
    "plt.axis('off')\n",
    "# Set title of the image\n",
    "plt.title(\"/r/Bitcoin\", fontsize = 48, color=\"Green\", pad=20)\n",
    "\n",
    "# Send it\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a50783-a732-4a07-942d-3575cdd65d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea206434-a590-4715-aeab-bb1f35468f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
